{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"build_model_and_run.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMSYdLW2faIdU4/XCd9dtQM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"xCX6HJ_mll-M","colab_type":"code","colab":{}},"source":["'''\n","Terminal tool for defining an ANFIS model and training it without getting to code.\n","This only allows a small set of control over the creation and fitting of the model,\n","compared to all the tools tensorflow and keras provides\n","'''\n","\n","import argparse\n","import csv\n","import ANFIS_Model\n","\n","def read_input_data(input_file):\n","    with open(input_file) as f:\n","        reader = csv.reader(f)\n","        input_data, output_data = [], []\n","        for row in reader:\n","            input_data.append([float(i) for i in row[:-1]])\n","            output_data.append(float(row[-1]))\n","        num_inputs = len(input_data[0])\n","    return num_inputs, input_data, output_data\n","\n","def train(num_inputs, num_mf, epochs, input_data, input_target, optimizer, model_name, **kwargs):\n","    model = ANFIS_Model.Model(num_inputs, num_mf, type_mf=type_mf)\n","    model.compile(optimizer=optimizer, loss='mean_squared_error')\n","    model.fit(input_data, input_target, epochs)\n","    model.save(model_name)\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser(description='build and train an ANFIS Model\\\n","     based on Tekagi-Sugeno rules with the amount of inputs and membership functions\\\n","     you choose, as long as the number of mfs for each input is the same')\n","\n","    parser.add_argument('input_data', help='full path to csv file containing the\\\n","                        input data of the model. The last column of the file will\\\n","                        be considered the target and all the other ones features.\\\n","                        Check for data inconsistencies before training!')\n","\n","    parser.add_argument('num_mf', help='number of membership functions for the\\\n","                        inputs of the model', type=int)\n","\n","    parser.add_argument('epochs', help='number of epochs for training', type=int\n","\n","    parser.add_argument('optimizer', help='optimizer used in the training', type=str)\n","\n","    parser.add_argument\n","\n","    parser.add_argument('output', help='name of model', type=str)\n","\n","# TODO: Add callbacks and train_test_split as args in a nice way\n","\n","    args = parser.parse_args()\n","\n","    num_inputs, input_data, output_data = read_input_data(input_file=args.input_data)\n","\n","    train(args.num_inputs, args.num_mf, args.epochs, input_data, output_data, args.optimizer, args.output)\n"],"execution_count":null,"outputs":[]}]}